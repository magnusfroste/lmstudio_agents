# LM Studio Function Calling Example

This project demonstrates how to use LM Studio's function calling capability to enable an LLM (like Qwen) to multiply two numbers using a Python function.

## Project Structure

This project provides a modular framework for interacting with an LLM using function calling in LM Studio. The structure is designed to be easily extensible for adding new tools:

- **`lm_tool_interaction.py`**: The main script that handles chat interactions with the LLM and routes tool calls to the appropriate functions.
- **`tools/`**: A directory containing modules for each tool/function:
  - **`math_operations.py`**: Contains functions for mathematical operations like multiplication.
  - **`web_requests.py`**: Contains functions for making HTTP requests.
  - **`database_operations.py`**: Contains functions for querying a SQLite database of product sales.
- **`create_sales_database.py`**: A utility script to generate a sample SQLite database with product sales data.
- **`product_sales.db`**: The SQLite database file containing sample sales data (generated by running `create_sales_database.py`).

## Prerequisites

- **LM Studio**: Ensure LM Studio is installed and running as a server with a model like Qwen2.5-7B-Instruct-GGUF loaded.
- **Python**: Version 3.6 or higher.
- **OpenAI Library**: For interacting with LM Studio's API.
- **Requests Library**: For making HTTP requests.

## Setup

1. **Clone the Repository**: If you haven't already, clone this repository to your local machine.
2. **Run the Installation Script**: Execute `./install.sh` to set up the virtual environment, install dependencies, and create the sample sales database. This script will:
   - Check if Python 3.6 or higher is installed.
   - Create a virtual environment named `venv`.
   - Activate the virtual environment and install required packages (`openai` and `requests`) from `requirements.txt`.
   - Run `create_sales_database.py` to generate the sample database with 50 sales records.
3. **Activate the Virtual Environment**: If the script doesn't work or you prefer manual setup, run `source venv/bin/activate` (Mac/Linux) or `venv\Scripts\activate` (Windows) after ensuring the virtual environment is created.

**Note**: Ensure LM Studio is installed and running as a server on `localhost:1234` with a model like Qwen2.5-7B-Instruct-GGUF loaded before starting the application. On macOS, LM Studio supports MLX models, which are optimized for Apple Silicon and can provide better performance. You can load MLX models like `MLX-Qwen2.5-7B-Instruct` for enhanced efficiency on Mac.

## Running the Project

Run the main script to start interacting with the LLM:

```bash
python lm_tool_interaction.py
```

**Interface Note**: The interaction with the LLM occurs through a terminal window (command line interface). After running the script, a chat-like interface will open in your terminal where you can type your messages to communicate with the LLM. This is not a web-based chat; it operates entirely within the terminal. Type your messages and press Enter to send them, and type `exit` to stop the interaction.

Type your messages to chat with the LLM, and type `exit` to stop.

**Note**: Before querying sales data, ensure the sample database has been created. The installation script now handles this automatically, but if you need to regenerate it, run `python create_sales_database.py` manually.

**Asking About Sales Data**: You can ask the LLM about sales data using natural language questions like 'How much was sold in May 2025?' or 'What were the sales for last month?'. The LLM will interpret your request and retrieve the total sales revenue and number of items sold for the specified month. Note that the sample data covers approximately the last three months from the date the database was created, so queries for future dates or much older dates may return no results.

**Advanced Sales Queries**: Beyond monthly totals, you can also ask for:
- A list of all unique products sold with quantities and total revenue (e.g., 'List all sold products' or 'Show me the sales inventory').
- The top most expensive product sales with details like price and sale date (e.g., 'What are the 5 most expensive products sold?' or 'Show top 3 highest priced sales').

**Discovering Available Functions**: If you're unsure about what I can do, simply ask 'What functions do you support?' or 'List available tools'. I will provide a list of all the tools and functions I can use to assist you, along with a brief description of each.

## Extending the Project

To add more functions/tools for the LLM to use, follow these steps:

1. **Create a New Tool Module**: Add a new Python file in the `tools/` directory for your function (e.g., `tools/new_tool.py`).
2. **Define the Function**: Write your function with appropriate docstrings and type hints. For example:
   ```python
   def new_function(param1: str) -> str:
       """Description of what the function does."""
       # Function implementation
       return result
   ```
3. **Add the Tool to the Tools List**: Update the `tools` list in `lm_tool_interaction.py` to include the new function:
   ```python
   tools = [
       # Existing tools
       {
           "type": "function",
           "function": {
               "name": "new_function",
               "description": "Description of what the function does.",
               "parameters": {
                   "type": "object",
                   "properties": {
                       "param1": {
                           "type": "string",
                           "description": "Description of param1"
                       }
                   },
                   "required": ["param1"]
               }
           }
       }
   ]
   ```
4. **Update the Router**: Modify the `handle_tool_call` function in `lm_tool_interaction.py` to handle the new tool:
   ```python
   elif tool_name == "new_function":
       result = new_function(tool_arguments['param1'])
       return f"Result of new_function: {result}"
   ```
5. **Import the Function**: Ensure the new function is imported at the top of `lm_tool_interaction.py`:
   ```python
   from tools.new_tool import new_function
   ```

This modular structure allows you to keep adding new tools without cluttering the main script, maintaining a clean and scalable codebase.

**Example Additional Tool**: A tool for querying sales data by month has been successfully added. You can ask the LLM questions like "How much was sold in March 2025?" by specifying the month in 'YYYY-MM' format (e.g., '2025-03'). The tool will return the total sales revenue and the number of items sold for that month, based on the sample data in the database.

Additionally, tools for more flexible database interaction have been implemented:
- `list_all_sold_products`: Returns a list of all unique products sold, showing how many units of each were sold and the total revenue generated.
- `get_top_expensive_products`: Retrieves the top most expensive individual sales (defaulting to top 5), including product name, price, and sale date.
- `list_available_tools`: Allows users to see all supported functions and capabilities of the LLM. Simply ask 'What functions do you support?' or 'List available tools' to get a comprehensive list of what I can do to assist you.

## Extending with More Functions (Tool Calling)

You can extend this project by adding more functions that the LLM can call as tools. Here's how to add a new tool for making an HTTP request:

1. **Define the New Function**: Add a new function in `web_requests.py` to handle HTTP requests. For example:
   ```python
   import requests

   def make_http_request(url: str) -> str:
       """Make an HTTP GET request to the specified URL and return the response text."""
       try:
           response = requests.get(url)
           response.raise_for_status()
           print(f"HTTP request to {url} successful")
           return response.text[:500] + "..." if len(response.text) > 500 else response.text
       except Exception as e:
           print(f"Error making HTTP request to {url}: {str(e)}")
           return f"Error: {str(e)}"
   ```

2. **Add the Tool to the Tools List**: Update the `tools` list to include the new function:
   ```python
   tools = [
       {
           "type": "function",
           "function": {
               "name": "multiply_numbers",
               "description": "Multiply two numbers and return the result.",
               "parameters": {
                   "type": "object",
                   "properties": {
                       "a": {
                           "type": "number",
                           "description": "The first number"
                       },
                       "b": {
                           "type": "number",
                           "description": "The second number"
                       }
                   },
                   "required": ["a", "b"]
               }
           }
       },
       {
           "type": "function",
           "function": {
               "name": "make_http_request",
               "description": "Make an HTTP GET request to a specified URL and return the response.",
               "parameters": {
                   "type": "object",
                   "properties": {
                       "url": {
                           "type": "string",
                           "description": "The URL to make the HTTP GET request to"
                       }
                   },
                   "required": ["url"]
               }
           }
       }
   ]
   ```

3. **Update the Chat Loop to Handle the New Tool**: Modify the `main()` function to process calls to the new tool:
   ```python
   # Check if the assistant wants to call a tool
   if assistant_message.tool_calls:
       for tool_call in assistant_message.tool_calls:
           if tool_call.function == "multiply_numbers":
               args = json.loads(tool_call.arguments)
               result = multiply_numbers(args["a"], args["b"])
               messages.append({
                   "role": "tool",
                   "content": str(result),
                   "tool_call_id": tool_call.id
               })
               # Get the final response from the model after tool execution
               final_message = chat_with_model(messages)
               messages.append(final_message)
               print(f"Assistant (after calculation): {final_message.content}")
           elif tool_call.function == "make_http_request":
               args = json.loads(tool_call.arguments)
               result = make_http_request(args["url"])
               messages.append({
                   "role": "tool",
                   "content": result,
                   "tool_call_id": tool_call.id
               })
               # Get the final response from the model after tool execution
               final_message = chat_with_model(messages)
               messages.append(final_message)
               print(f"Assistant (after HTTP request): {final_message.content}")
   ```

4. **Install Additional Dependencies**: If your new function requires additional libraries (like `requests` for HTTP requests), install them in your virtual environment:
   ```bash
   source venv/bin/activate  # On macOS/Linux
   # OR
   venv\Scripts\activate  # On Windows
   pip install requests
   ```

5. **Update System Message**: Optionally, update the system message to inform the model about the new capability:
   ```python
   messages = [
       {"role": "system", "content": "You are a helpful assistant that can perform calculations and make HTTP requests. Use the multiply_numbers tool for multiplication and make_http_request tool for fetching web content."}
   ]
   ```

Now, when interacting with the model, you can ask it to fetch content from a URL, for example: "Can you get information from https://api.example.com/data?" and it will call the `make_http_request` function to retrieve the data.

Remember to handle errors appropriately in your functions and limit response sizes if necessary to avoid overwhelming the model with too much data.
